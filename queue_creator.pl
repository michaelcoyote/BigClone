#!/usr/bin/perl
# 
# queue_creator.pl
# Job Queue processor
# 
#
# The object of this script is to take a backup pool (or multiple 
# backup pools) and create a queue for the savesets to 
# clone a single clone pool.
#
#
# TODO 
# use of program flags for program control (cloning/staging, number 
# 	of drives, days back, etc.)
# reduce/remove use of tempfiles by using arrays ?
# logging to logfiles
# use subroutines to simplify program flow and make expansion easier
#
# long term:
# expand to cover multiple source and destination pools
#
## Best Practices.  
# Do not remove or disable without good documented reason.
#


###### 
# Do not remove or disable without good documented reason.
#
use strict;
use warnings;
# addtional libraries
use Getopt::Std;
use File::Path;

use vars qw($NSRSERVER $CLONETMP $DEBUG $NSRMMINFO $TEST 
$LOGFILE $LOGLOC $NSRBIN $CONFIG %options $PRIORITY
$i $LOGFILE $mmquerystring $QUEUEDIR @POOLS $DESTPOOL
 $QUEUES $DAYS @ssidout %worklist $volume);

#
#
# the number of queues to create during the clone process.
# this number can be adjusted up or down as needed to provide 
# control the queue creation.  
# More queues create more smaller clone operations, 
# while fewer queses create larger clone operations.
$QUEUES="4";

# How many days back will we clone?
$DAYS="-14";

#
# what source pool or pools will we clone/stage from
# this is a quoted comma seperated list ("item1","item2")
@POOLS=("Plat");

#
# what backup clone pool will be our destination
# this pool must be a backup clone
$DESTPOOL="PlatClone";

#
#
# Priority
# Take saveset SSID queue files from the queue directory by priority
# priority by file extension (*.qf1 highest to *.qf9 lowest)
# qf file header should contain: 
# creation date(YYYYMMDDHHMM), last priority([1-9], retries
# Levels:
# qf1 – reserved of future use/unused
# qf2 – manual emergency clone 
# qf3 – highest priority
# qf4 – high priority
# qf5 – medium priority
# qf6 – medium low priority
# df7 – low priority
# qf8 – reserved of future use/unused
# qf9 – reserved of future use/unused
#
$PRIORITY=4;


#
# the FQDN of the NetWorker server
$NSRSERVER="bocntbk12.boc.chevrontexaco.qnet";
#
#
# Where the queuefiles live
$QUEUEDIR="./queuedir";

# Logs go here
$LOGLOC="./log";
#
# find our NetWorker executibles  here
$NSRBIN="c:/Progra~1/Legato/nsr/bin";

# lockfile to disallow multiple copies
#$LOCKDIR="./lock";

# logfile for clone process
$LOGFILE="./log/queue_creator.log";


# Location of nsradmin command
$NSRMMINFO="$NSRBIN/mminfo";

# debug
$DEBUG=0;

##
# this should not be changed unless you understand what you are doing
# the list of savesets that will be replicated are generated by querying
# mminfo (1).  You should have a good understanding of mminfo query
# strings and how they work before modifying this
#
# see the command reference/man page for the mminfo command
# 
$mmquerystring="!incomplete, savetime<$DAYS days ago,copies<2";


####  Code starts here.  No user set vars below this line
#
#
#
#####
# set up our options
#
# -D: debug
# -c: config file
# -t: test only, works very nice with -D
#
#
getopts('Dstc:',\%options);

####
# make command line switches do something
#
# just makes code easier to read, really.
if ($options{D}) { $DEBUG=1;}
if ($options{t}) { $TEST=1;}
# 



#####
# canned functions
#
# logme function
# usage:
# &logme(message => "subroutine: $status", level => "DEBUG");
sub logme {
	# set up the data structure to hold the data to log
	my %args = (
		'message'        => '',
		# default level is INFO
		'level'          => 'INFO',
                @_,
	);
	# use GMT (ZULU) time to log. localtime() may be substituted for gmtime() as desired.
	my $date=gmtime();
	# preset printing to stdout off
	my $use_stdout=0;
	# if we can't open a logfile to append send output to stdout
	$use_stdout=1 unless(open(LOGFILE, ">>$LOGFILE"));
	# turn off buffering on the filehandle
	{ my $logfh = select LOGFILE;
		$| = 1;
		select $logfh;
	}

	chomp($date);
	# write to stdout
	# select((select(DEV), $| = 1)[0]); 
	if ( $use_stdout ) {
		printf("%s: %s - %s\n",$date,$args{level},$args{message});
	# write to our logfile
	}else {
		printf(LOGFILE "%s: %s - %s\n",$date,$args{level},$args{message});
		close(LOGFILE);
	}
} #end logme subroutine

# a quick function to log and die a process on error
sub dielog {
	my ($error) = @_;
	
	logme(message => "$error", 
		level => 'ERROR');
	logme(message => "queue_runner ended");
	die "$error\n";
 
}
# use to clear the lockfiles
#sub dieunlock {
#	# unlock and log
#	my ($error) = @_;
#	unlink ($LOCKFILE);
#	logme(message => "$LOCKFILE Removed");
#	unlink ("$LOCKFILE") or dielog ("Error removing $LOCKFILE: $!");
	# log the error
#	logme(message => "$error", 
#		level => 'ERROR');
#	logme(message => "queue_runner ended");
#	die ("$error\n");
#} # end dieunlock()
########

#####
# standard operations
#
# log if there is a logfile
if ($LOGFILE) {
	print "using $LOGFILE as the logfile\n";
	#
	# put a visual indicator in the log to show the start of the run
	logme ( message => "################################################",
		level=> "START");
	logme ( message => "$0 starting. PID: $$");
}
else {
	print "logging to console\n";
}

##### read in config files
if ($options{c}) {
	if ( -e "$options{c}") { 
		print "reading $options{c}\n";
		no strict 'refs';
		open ( CONF, "$options{c}") || die "cannot open config: $!\n";
		my $conf = join "", <CONF>; 
		close CONF;
		eval $conf;
		die "Couldn't eval config file: $@\n" if $@;
		print "config file loaded\n";
	} else {print "Config file not found, using defaults\n";}
}
#####


###
if ($DEBUG) {
use Data::Dumper;
# log if we have debug on
logme ( message => "Debug on... level:$DEBUG");
}



#################
#
# Main line of the program
#
#
# Create the tempdir
if (!-d $QUEUEDIR) { 
    mkpath ($QUEUEDIR) || dielog("ERROR creating $QUEUEDIR: $!");
}


ss_sort(queue_compare(ss_gather(@POOLS)));


########
#
#
#
###
#
#
# Saveset list gathering Loop
# obtain list of complete Save Set IDs matching desired criteria 
# and seperate them into nonspanning and spanning savesets
# and dump into correct files
sub ss_gather {
	foreach my $pool (@_){
		logme(message=> "ss_gather",
			level=>"DEBUG");
	
		#
		# read in the output of mminfo and dump into filehandle SSID.
		# output is 4 comma seperated fields.  If you change the 
		# reporting (-r) output of mminfo you will need to address this 
		# in the sorting loop

		logme(message=> "running mminfo: $NSRMMINFO -s $NSRSERVER -xc, -r sumflags,volume,ssid,cloneid   -q \"pool=$pool\" -q \"$mmquerystring\"",
		level=> "DEBUG") if $DEBUG;
		open (SSID, "$NSRMMINFO -s $NSRSERVER -xc, -r sumflags,volume,ssid,cloneid   -q \"pool=$pool\" -q \"$mmquerystring\"|") || dielog( "Problem contacting mminfo: $!");

		# for testing
		#open ( SSID, "testfile.txt") || die "no testfile.txt\n";
	
		#
		# read the 4 fields and dump to the array @ssidtmp.
		my @ssidtmp=<SSID>;
	
		# for debug
		if ($DEBUG > 6) {
			foreach(@ssidtmp) {
				logme(message=>"ssidtmp: $_",
					level=> "DEBUG");
			}
		}
	
		close (SSID);

		return (@ssidtmp);
	}


} # end ss_gather()
#
# 
#
# compare incoming list to queue and filter previously 
# selected savesets
sub queue_compare {
	my @newssids=@_;
	my @oldssids;
	my @uniquessids;
	logme(message=>"queue_compare");
	#print(Dumper(@newssids)."\n");
	# get all files in the queue directory 
	# and dump them to an array of filenames
	#
	# all the files are formatted 
	# ssid/cloneid
	my @qfiles = <$QUEUEDIR/*>;
	foreach my $qf (@qfiles) {
		logme(message=>"reading $qf",
			level=>"DEBUG") if $DEBUG;
		# just log error and continue
		open (QF, "< $qf") or logme(message=>"cannot open $qf: $!",
		level=>"ERROR");
			my @tqf = <QF>;
			foreach my $qline (@tqf) {
				#print "queue line: $qline\n";
				if ($qline =~ /^[0-9]..*/) {
					chomp($qline);
					my @baz = split("/",$qline,2);
					# only push the SSID portion
					push (@oldssids, $baz[0]);
					logme(message=>"SSID queued: $baz[0]",
						level=> "DEBUG") if $DEBUG;
				}
			}
	}
	#
	#print(Dumper(@oldssids)."\n");
	# read all the ssids and place them into an array of ssids
	# all the records are formatted 
	# flags,volume,ssid,cloneid
	# Find SSIDs in @newssids that arent in @oldssids
	my %seen;
	# build lookup table
	@seen{@oldssids} = (1);
	#print("seen ssids array:\n".Dumper(%seen)."\n");
	foreach my $ss (@newssids) {
		chomp($ss);
		my @foo = split (',',$ss,4);
		logme(message=>"looking for SSID: $foo[2]",
			level=>"DEBUG") if $DEBUG;
    		unless (defined($seen{$foo[2]})){
			logme(message=>"SSID not seen: $foo[2]",
				level=>"DEBUG") if $DEBUG;
			# reconstitute the records of only the unique SSIDs
			push(@uniquessids, "$foo[0],$foo[1],$foo[2],$foo[3]");
		}
	}
	#print("unique ssids array:\n".Dumper(@uniquessids)."\n");
	return(@uniquessids);
}
#
#
# Sorting Loop.
# here I take the array from the Saveset gathering Loop above and sort 
# though it line by line.  All i'm doing here is reading in the list 
# of savesets and sorting out the ones i want like complete and "head" 
# savesets and creating a "worklist" keyed against the tape volume ID
# TODO
# a possible optimization might be to flag "head" (spanning multiple tapes)
# savesets for running after "complete" savesets (savesets residing on 
# one tape). This could make for faster cloning on systems where the 
# savesets are smaller
#
sub ss_sort {
	logme(message=> "Sorting SaveSets");
	foreach (@_) {
		print "." if $DEBUG;
		my ($flags, $volume, $ssid, $cloneid) = split (',');
		#print "flags: $flags\n";
		#
		if ($flags eq "flags") {  
			next; # skip the column first row
		}
		if ($flags =~ m/^c/) {  	# find complete savesets
			# for testing
			#print "DEBUG: $ssid \n";
			#print COMP "$volume,$ssid\\$cloneid\n";
			#
			# Print an "x" per complete save set to show progress.  
			# this can be commented out if desired
			print "x" if $DEBUG;
			
			# Dump the ssid and cloneid pair into 
			# a hash of hashes using the volume 
			# number as the key
			$worklist{$volume} = [] unless exists $worklist{$volume};
			logme(message=>"Volume: $volume - Found head SSID: $ssid ",
			level=>"DEBUG") if $DEBUG > 4;
			push(@{$worklist{$volume}},$ssid."/".$cloneid);
			#
			next; 
		}
		if ($flags =~ m/^h/) { # find head of spanning savesets
			# for testing
			#print "$ssid is not continious\n";
			
			# Print a "+" per "spanning" saveset to show progress
			# this can be commented out if desired
			print "\+" if $DEBUG;
			
			#
			#
			$worklist{$volume} = [] unless exists $worklist{$volume};
			push(@{$worklist{$volume}},$ssid."/".$cloneid);
			next; 
		}

	} ## Close foreach()
	print "\n";


	# Drive Queue Loop
	# loop through each volume and sort into a number of queues 
	#
	my %queue;
 	# TODO document the outcome of this process
	foreach $volume (sort keys %worklist){
		#
		($i++ >= $QUEUES) && ($i=1);
		logme(message=>"Queue number: $i",
		level=>"DEBUG") if $DEBUG;
		logme(message=> "Volume: $volume",
			level=>"DEBUG") if $DEBUG;
		my @sssort = @{$worklist{$volume}};
		foreach my $sscl (@sssort) {
			my $q=$i;
			chomp($sscl);
			logme(message=>"queue $q SSID: $sscl",
				level=>"DEBUG") if $DEBUG;
			push (@{$queue{$q}},$sscl );
		}
	}

# Queue File Loop
# Loop through and create queuefiles that queue_runner.pl
# can read from.
	foreach my $qout (sort keys %queue ) {
		my $queuefile="$QUEUEDIR/ssq-$DESTPOOL-$$-q$qout-t0.qf$PRIORITY";
		logme (message=>"saving queue $qout to: $queuefile");
		open ( SSDQ, ">>$queuefile") || dielog ("Error writing queuefile $$queuefile:$!");
		my @ssids = @{$queue{$qout}};
		foreach my $s (@ssids) {
		print (SSDQ $s."\n");
		}
		close (SSDQ);
	}
} # end ss_sort()
# put a visual indicator in the log to show the end of the run
logme(message=>"PID:$$ ##################################",level=>"STOP");
# clear the line
print "\n";
#
